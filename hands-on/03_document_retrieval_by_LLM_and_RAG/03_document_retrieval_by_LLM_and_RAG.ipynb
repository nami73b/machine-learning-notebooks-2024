{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114b6c74-b6b7-4aa2-aac1-ec2bc6c013aa",
   "metadata": {},
   "source": [
    "# RAGを用いた文章検索\n",
    "\n",
    "このハンズオンでは、GoogleのGemini Proを用いた会話応答文の生成方法と、  \n",
    "RAGを用いて特定の文章を参照して応答するようにする方法を学んでいきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767e91f-d154-4131-bdc8-46a9c361373c",
   "metadata": {},
   "source": [
    "まず必要なライブラリをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1baac-7435-49cd-b5b2-fc21ba6f6b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.1.13 langchain-google-vertexai==0.1.2 chromadb sentence-transformers lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625ed96-80d3-4121-b9a8-0b490d3d2a0f",
   "metadata": {},
   "source": [
    "notebook全体で使うライブラリを読み込んでおきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9e74d-fe49-4cd8-85f9-6247df7df65c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from gcs_utils import GcsUtils\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb707dc4-7eec-4703-9cfe-9f53cedeb7c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "データセットが一部GCSにあるので、GCSを読み込む部分も予め定義しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab2356-dd92-453b-997c-0545677ca861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 研修用gcs環境が使える場合のみTrueにしてください\n",
    "use_image = False\n",
    "# use_image = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f26c35-169b-4518-bf34-9816105a6c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"hr-mixi\"\n",
    "BUCKET_NAME = \"mixi-ml-handson-2024\"\n",
    "bucket = GcsUtils(\n",
    "    project_id=PROJECT_ID,\n",
    "    bucket_name=BUCKET_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4741f2e0-4e1f-41fa-9471-9b796bc87834",
   "metadata": {},
   "source": [
    "# Google Gemini Pro 1.5を用いた文章生成\n",
    "では、試しにGemini Proを用いて文章生成を行ってみましょう。  \n",
    "なお、今回はLLMsを用いた開発でよく使われるLangChainを使ってGeminiを呼び出しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906414a-c433-4c87-9b62-290968b9086d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "\n",
    "model_name = \"gemini-1.5-pro-preview-0409\"\n",
    "gemini_model = ChatVertexAI(model_name=model_name, location='asia-northeast1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8f77a-c453-4e5a-9be9-3772e4a5cffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_message(text, model=gemini_model):\n",
    "    return model([HumanMessage(content=[text])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafd559-0249-450a-8c14-154d72b327d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# questionを任意で変更して、モンストのキャラクターについての質問をしてみてください。また、参考文献を明示するような指示も入れてください。\n",
    "question = 'モンストのパンドラについて教えてください。 また、参考にした情報を明示してください。'\n",
    "\n",
    "response = get_message(question)\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493935a3-e50f-4e3d-afa5-e955406621c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "文章の生成はできましたでしょうか？ 生成できた場合、内容は正しそうですか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074d1c1-d0fa-4006-84ae-ea65005eba74",
   "metadata": {},
   "source": [
    "# 文章生成の問題点\n",
    "\n",
    "文章生成の結果は、一見正しそうな結果が返ってきてそうに見えるかと思います。  \n",
    "しかし、この生成された文章には以下の問題点があります。  \n",
    "\n",
    "1. **検索結果に精度が左右される**  \n",
    "デフォルトのquestionで生成した結果には、`参考情報`として、モンスト公式サイトやAppMedia、GameWithなどが  \n",
    "挙げられていました。この結果から、Gemini Proは、モンストの情報を学習していたのではなく、  \n",
    "質問を応答する前に検索を行い、その結果の情報を渡しているため、返答ができていると考えられます。  \n",
    "これらの検索はこちらが指定したものではく、間違っていたり、古いものを参照してしまう可能性があり、  \n",
    "正確な情報を求められる検索では適切ではなくなってしまいます。\n",
    "\n",
    "\n",
    "2. **ハルシネーションが起こる**  \n",
    "デフォルトのquestionで生成した結果を正確に見てみると、一部間違っている情報があることがよくあります。  \n",
    "一例を挙げると、例えば`パンドラ`が、闇属性なのに`火属性のガチャ限定キャラクター`となっていたり、  \n",
    "`進化`に実際は所持していないギミックである`アンチダメージウォール`が入ってしまっていることなどがあります。  \n",
    "このように、文章生成で返答する文は、一見違和感のない文章で、間違っている内容を出力してしまうので注意が必要です。  \n",
    "またこのような現象のことを、ハルシネーションといいます。  \n",
    "\n",
    "このような問題に対するアプローチとして、前のセクションで取り組んだTransfer Learningや  \n",
    "Fine-Tuningといった手法もありますが、LLMはモデルのパラメータが膨大なため、一部の層を  \n",
    "再学習させるだけでも、相当なコストがかかります。  \n",
    "\n",
    "そのため、このパートでは、LLMで特定文章を参照してもらいたい時によく使われる  \n",
    "`RAG(Retrieval-Augmented Generation)`という手法を用いていきます。  \n",
    "RAGは関連するドメインの文章を予めベクトル化し、質問文のベクトルと照らし合わせて類似度検索を行い、  \n",
    "関連するドメインの文章を質問文と一緒にLLMの入力に与えることで、その情報を考慮した回答を生成します。  \n",
    "\n",
    "では、その仕組みをみていきましょう。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f7efa-cc1d-4f7e-8d91-ab41ef6f62f7",
   "metadata": {},
   "source": [
    "# データセットの確認\n",
    "まず、今回RAGを使って覚えさせる情報が入っているcsvを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05e878-b6ea-4e44-8ecb-ff29a804c5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 今回使うデータセットの読み込み\n",
    "df = pd.read_csv('monst_char_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97c19b-534c-4dde-abb5-099e36ba58de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 中身の確認\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3968d-73c9-418e-a9c2-f8d07512f830",
   "metadata": {},
   "source": [
    "中身を見てみると、モンストのキャラクター情報や、一言メッセージ、\n",
    "キャラの説明、性格や誕生日等の情報があります。  \n",
    "また、image_summariesには、キャラクターの画像を説明しているテキストがあります。  \n",
    "これらのデータセットは、[モンストディクショナリー](https://dic.xflag.com/monsterstrike/)を参考に作られているので、確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94747cff-1c3e-4b7a-979a-684a07ef19e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 各要素におけるdictの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eabd44-fc20-42b6-9c75-e834abac18ee",
   "metadata": {},
   "source": [
    "次に、RAGに合わせて、データの分割をおこなっていきます。  \n",
    "ここでは、構成する要素に合わせてcsv(df)データから、  \n",
    "text_dict、image_dict、metadata_dictの3つを作っていきます。  \n",
    "それぞれの役割は以下の通りです。  \n",
    "\n",
    "- **text_dict**  \n",
    "キャラクター毎のテキスト情報がまとめられており、主にこれをベクトル化していくことで検索を行う。\n",
    "- **image_dict**  \n",
    "キャラクター毎の画像の名前と説明が入っており、関連画像を参考情報としてgemini proに入力することで検索を補助する。\n",
    "- **metadata_dict**  \n",
    "metadataとして使われるものがまとめられており、主に検索時に、metadataを使うことでフィルタリングを行う。\n",
    "\n",
    "では、実行していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf966d88-17c5-4bde-ad63-caa8c76c5c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dicts_from_csv(df):\n",
    "    image_name_list = []\n",
    "    desc_list = []\n",
    "    text_list = []\n",
    "    metadata_name_list = []\n",
    "    metadata_birthday_list = []\n",
    "    metadata_sex_list = [] \n",
    "\n",
    "    for index, row in df.iterrows():         \n",
    "        # image_dict の作成 (既にあるsummariesとnameだけなので、名前だけ作成)\n",
    "        image_name_list.append(f\"{row['name']}\" if pd.notnull(row['name']) else \"\")\n",
    "\n",
    "        # text_dict\n",
    "        text_elements = [\n",
    "            f\"名前: {row['name']}\" if pd.notnull(row['name']) else \"\",\n",
    "            f\"一言: {row['voice']}\" if pd.notnull(row['voice']) else \"\",\n",
    "            f\"性格: {row['personality']}\" if pd.notnull(row['personality']) else \"\",\n",
    "            f\"誕生日: {row['birthday']}\" if pd.notnull(row['birthday']) else \"\",\n",
    "            f\"好きなもの: {row['favorite']}\" if pd.notnull(row['favorite']) else \"\",\n",
    "            f\"苦手なもの: {row['weak_point']}\" if pd.notnull(row['weak_point']) else \"\",\n",
    "            f\"性別: {row['sex']}\" if pd.notnull(row['sex']) else \"\",\n",
    "            f\"プロフィール: {row['description']}\" if pd.notnull(row['description']) else \"\",\n",
    "            f\"容姿: {row['image_summaries']}\" if pd.notnull(row['image_summaries']) else \"\"                \n",
    "        ]\n",
    "        text = ', \\n '.join(filter(None, text_elements))\n",
    "        text_list.append(text)\n",
    "        \n",
    "        # metadata_dict\n",
    "        metadata = {}\n",
    "        metadata_name_list.append(f\"{row['name']}\" if pd.notnull(row['name']) else \"\")\n",
    "        metadata_birthday_list.append(f\"{row['birthday']}\" if pd.notnull(row['birthday']) else \"\")\n",
    "        metadata_sex_list.append(f\"{row['sex']}\" if pd.notnull(row['sex']) else \"\")\n",
    "    \n",
    "    image_dict = {'name': image_name_list, 'summaries': df['image_summaries'].values.tolist()}\n",
    "    text_dict = {'texts': text_list}\n",
    "    metadata_dict = {'name': metadata_name_list, 'birthday': metadata_birthday_list, 'sex': metadata_sex_list}\n",
    "    \n",
    "    return image_dict, text_dict, metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2483ff4b-4bfe-44f3-a02a-f594fd76225a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dict, text_dict, metadata_dict = create_dicts_from_csv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2fc38-c986-48c7-94d7-7657db9c7a8c",
   "metadata": {},
   "source": [
    "これで、各構成要素に合わせたdictが用意できました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f0c5c-2f5c-4714-83dc-afc073fd33b5",
   "metadata": {},
   "source": [
    "# Retrieverの作成\n",
    "\n",
    "データが用意できたので、RAGを定義していきます。  \n",
    "RAGでは、Retrieverというものを使って、ドメインに関連情報する情報を検索します。　　\n",
    "\n",
    "今回は`ParentDocumentRetriever`と`SelfQueryRetriever`の2つを使って、関連情報の検索を行います。  \n",
    "ではそれぞれ、実装をみていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90088fc2-fd86-436f-a8a9-f8db571ba9be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ParentDocumentRetriever\n",
    "ParentDocumentRetrieverは、検索する際にドキュメントの文章から検索するのではなく、  \n",
    "検索用の文章を使って検索し、その検索用の文章に紐づいたドキュメントをLLMに渡すという  \n",
    "仕組みを実現するために定義されたRetrieverです。\n",
    "\n",
    "なぜこのような仕組みが用意されているかというと、一般的に、LLMに文章を渡す際は  \n",
    "詳細な情報も含めた文章を渡した方が精度が上がりやすいのですが、逆に検索用の文章は長すぎると、  \n",
    "特徴が平均化されてしまうため検索精度が下がってしまうという問題があります。  \n",
    "こういった問題に対処するために用意されているRetrieverとなります。\n",
    "\n",
    "今回はtext_dictのtextsに対して改行毎に区切って、それを検索用の文章としたいので、  \n",
    "textsを要素毎に改行で区切るように、修正していきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e478a0-5ac4-46dc-882d-78dbd9fac064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 改行で区切る\n",
    "# テキストデータを要素ごとに改行で区切る\n",
    "def reformat_text(text_list):\n",
    "    formatted_texts = []\n",
    "    for text in text_list:\n",
    "        formatted_text = \"\"\n",
    "        attributes = text.split(', \\n')\n",
    "        for attribute in attributes:\n",
    "            key, value = attribute.split(': ', 1)\n",
    "            # 余計な改行をスペースに置き換え\n",
    "            value = value.replace('\\r\\n', ' ').replace('\\n', '')\n",
    "            # カンマで区切られた値を結合\n",
    "            value = value.replace('、', '、 ')\n",
    "            key = key.replace(' ', '')\n",
    "            # 。で終わっている場合は改行\n",
    "            value = value.replace('。', '。\\n')\n",
    "            formatted_text += f\"{key}: {value}\\n\"\n",
    "        formatted_texts.append(formatted_text.strip())  # 末尾の不要な改行を削除\n",
    "    return formatted_texts\n",
    "\n",
    "# 整理されたテキストデータを取得\n",
    "formatted_texts = reformat_text(text_dict['texts'])\n",
    "text_dict['texts'] = formatted_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d275c-8281-46af-a775-2d06cc607be8",
   "metadata": {
    "tags": []
   },
   "source": [
    "うまく要素毎に改行で分割できているか確認してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27afb44-4e6a-482d-9794-79b9faf7b66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(str(text_dict['texts'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a308db-c8b9-43cc-a584-9fa70af56fa6",
   "metadata": {},
   "source": [
    "これで、データの準備は完了しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360a244-2e73-4a92-aba3-7816f3d7c75d",
   "metadata": {},
   "source": [
    "次に、ドキュメントをベクトル化(embedding)するためのモデルを用意します。  \n",
    "今回は、多言語対応モデルで日本語に対しての精度が高いと言われている[multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8336326-dd45-4c07-9000-02535dc1f8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_name = \"intfloat/multilingual-e5-large\"\n",
    "download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    local_dir = f\"model/{model_name.split('/')[-1]}\",\n",
    "    local_dir_use_symlinks=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb89e5-866b-41b2-ba1d-c50280c86972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_path = 'model/multilingual-e5-large'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba5672-8438-4e1b-a7b6-e5a0ee64c83e",
   "metadata": {
    "tags": []
   },
   "source": [
    "これでデータとベクトル化用のモデルの用意が終わったので、`ParentDocumentRetriever`を定義していきます。  \n",
    "まず、必要なmoduleをimportします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1b634-eb0e-4bba-9411-907b54990185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d3f87-3d74-485a-972d-592a65db70a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "次に、ParentDocumentRetrieverを取得するためのメソッドを定義します。  \n",
    "ここでは、主に3つの変数を定義し、ParentDocumentRetrieverに渡しています。\n",
    "- **vectorstore**  \n",
    "ベクトルで検索する時に使用される文章を`ChromaDB`を用いて格納する\n",
    "- **docstore**  \n",
    "ドキュメント単位での文章を`InMemoryStore`を用いて格納する\n",
    "- **splitter**  \n",
    "ドキュメントを改行で分割するために、`CharacterTextSplitter`を用いて定義する\n",
    "\n",
    "これら3つの変数をParentDocumentRetrieverに渡すことで、  \n",
    "Retriever内でドキュメントの改行毎にsubdocを作成し、vectorestoreに格納してくれるようになります。  \n",
    "\n",
    "最後にドキュメントをRetrieverに追加して、retrieverを返すまでがこのメソッドの全貌となります。  \n",
    "では、実際にメソッドを実行してみてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7eec3-6f06-4cee-b42c-9b50ea9a38e1",
   "metadata": {},
   "source": [
    "## TODO\n",
    "ParentDocumentRetrieverに適切なクラスインスタンスを指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc707cb-1bcb-4095-9453-ec8061926c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_parent_retriever(text_dict, embeddings=embeddings):\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=\"gemini-pro-text-rag\",\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "\n",
    "    # 元の文章を保存するためのストレージ\n",
    "    store = InMemoryStore()\n",
    "    id_key = \"doc_id\"\n",
    "    \n",
    "    # inputを改行で区切ってsubdocを作成するためのsplitterを定義する\n",
    "    child_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1, chunk_overlap=0)\n",
    "    \n",
    "    # TODO\n",
    "    retriever = ParentDocumentRetriever(\n",
    "        vectorstore=____, \n",
    "        docstore=____,\n",
    "        child_splitter=____,\n",
    "        id_key=id_key,\n",
    "        search_kwargs={\"k\": 10},\n",
    "    )\n",
    "    \n",
    "    # テキストデータをembedding、vectorstoreに格納する\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in text_dict[\"texts\"]]\n",
    "    # チャンクを保存する\n",
    "    for i, s in enumerate(text_dict[\"texts\"]):\n",
    "        if s != \"\":\n",
    "            retriever.add_documents(\n",
    "                [Document(page_content=s, metadata={id_key: doc_ids[i]})]\n",
    "            )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac20138-be17-457c-82d9-b99cc6d78180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 下記コードはsplit毎にlogが流れるので、実行後に最小化しても問題ないです。\n",
    "parent_retriever = get_parent_retriever(text_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256fb53-5c0e-410f-8bcc-f9301cb6157f",
   "metadata": {},
   "source": [
    "実行が完了したら、試しに投げてみましょう  \n",
    "textsの一番目のキャラクターのプロフィールを参考に、正しい検索ができているかクエリを投げてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f9da2-dac4-4961-90a7-f3805a62b9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(text_dict['texts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2a800-593a-4b34-9860-b4bcf26249c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_retriever.get_relevant_documents(\"工場現場巡りが好きなキャラクターを教えてください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921612e-a7b5-486b-bda0-4466644970cc",
   "metadata": {},
   "source": [
    "一番類似度が高いものとtextsに入っているもの(クラフト)が一致しているでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e586fe-61dc-4b56-9577-916f378d02ab",
   "metadata": {},
   "source": [
    "## SelfQueryRetriever\n",
    "SelfQueryRetrieverは主にMetadataフィルタイングをしたい時に使用されるRetrieverとなります。  \n",
    "このRetrieverを使うと、metadataを含む質問がされた場合に、中のLLMがその質問を解析し、  \n",
    "metadataに応じたフィルタを作ってくれるようになります。  \n",
    "LLMでの検索は、一致検索の精度に難があるので、このようにフィルタリングを行うことで、  \n",
    "`誕生日`や`性別`といったものの一致検索に対しても高い精度を保てるようになります。  \n",
    "\n",
    "では、実装を見ていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05b8bf7-7c45-4817-aae9-3f26fde5b311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5512ba-f5f0-4e8b-83ee-be9a57b3267c",
   "metadata": {},
   "source": [
    "検索の精度の関係上、日付に当たるbirthdayを、`mm-dd`方式にし、また、月や日にち単体でも  \n",
    "検索できるようにそれぞれを別のものとして再定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cab02b-b435-49a3-8b4b-19692fe539e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_date(date_str):\n",
    "    # 日付を mm-dd, month, dayを出力する\n",
    "    try:\n",
    "        date = datetime.strptime(date_str, '%m/%d')\n",
    "        return date.strftime('%m-%d'), str(int(date.strftime('%m'))), str(int(date.strftime('%d')))\n",
    "    except ValueError:\n",
    "        # 日付の形式が正しくない場合はNoneを返す\n",
    "        return \"\", \"\", \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c904ed1-d999-45f6-8021-cea515bfe74d",
   "metadata": {
    "tags": []
   },
   "source": [
    "では、SelfQueryRetrieverを取得するためのメソッドを定義します。  \n",
    "今回はドキュメントを格納するvectoresotreのみ定義し、その中にドキュメントを追加していくのですが、  \n",
    "そこでmetadataを定義するようにします。　　\n",
    "\n",
    "metadataは以下の5つを定義しています。\n",
    "- **name** 名前\n",
    "- **birthday** 誕生日\n",
    "- **birthday_month** 誕生月\n",
    "- **birthday_day** 誕生日の日にち\n",
    "- **sex** 性別\n",
    "\n",
    "また、同時に画像の検索を行っているので、画像の要約もvectorestoreに追加しており、  \n",
    "その際metadataに`容姿`という情報を追加しています。  \n",
    "後の処理で、LLMでの検索時に`容姿`を含むmetadataの情報が関連する資料として取得できた場合、  \n",
    "そのキャラクターの画像を出力するという構成をとっているため、このようなmetadataを追加しています。\n",
    "\n",
    "これら3つの変数をParentDocumentRetrieverに渡すことで、  \n",
    "Retriever内でドキュメントの改行毎にsubdocを作成し、vectorestoreに格納してくれるようになります。  \n",
    "\n",
    "また、metadataとして登録したものはAttributeInfoを使って属性の定義をする必要があるので、  \n",
    "メソッド内でその定義を行い、metadataのフィルタ生成をするためのLLMとして`gemini pro`を指定します。  \n",
    "最後に定義したものをRetrieverに渡し、そのRetrieverを返すまでがこのメソッドの処理になります。  \n",
    "\n",
    "では、このメソッドも実行していきましょう。\n",
    "\n",
    "## TODO\n",
    "SelfQueryRetrieverに適切なクラスインスタンスを指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c230384-8f32-452f-ae14-fe8983361fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_self_query_retriever(text_dict, image_dict, metadata_dict, examples, model_name=\"\"):\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=\"gemini-pro-multi-rag\",\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "\n",
    "    # 元の文章を保存するためのストレージ\n",
    "    store = InMemoryStore()\n",
    "    id_key = \"doc_id\"\n",
    "    \n",
    "    # テキストデータをembedding、vectorstoreに格納する\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in text_dict[\"texts\"]]\n",
    "    \n",
    "    # チャンクを保存する\n",
    "    # この時、metadataとして定義したものをtextと一緒にdocumentに追加しておく\n",
    "    for i, s in enumerate(text_dict[\"texts\"]):\n",
    "        if s != \"\":\n",
    "            birthday, birthmonth, birthday_day = format_date(metadata_dict['birthday'][i])\n",
    "            vectorstore.add_documents(\n",
    "                [Document(page_content=s, metadata={\n",
    "                    id_key: doc_ids[i],\n",
    "                    \"name\": metadata_dict['name'][i],\n",
    "                    \"birthday\": birthday,\n",
    "                    \"birthday_month\": birthmonth,\n",
    "                    \"birthday_day\": birthday_day,                    \n",
    "                    \"sex\": metadata_dict['sex'][i]                   \n",
    "                })]\n",
    "            )\n",
    "            \n",
    "    print(\"Text Data Stored!!\")\n",
    "\n",
    "    # 画像の要約をembedding、vectorstoreに格納する\n",
    "    img_sum_ids = [str(uuid.uuid4()) for _ in image_dict[\"summaries\"]]\n",
    "    \n",
    "    # チャンクを保存する\n",
    "    # この時、metadataとして名前と'容姿'という情報を追加しておく\n",
    "    for i, summary in enumerate(image_dict[\"summaries\"]):\n",
    "        if s != \"\":\n",
    "            vectorstore.add_documents(\n",
    "                [Document(page_content=summary, metadata={\n",
    "                    id_key: img_sum_ids[i],\n",
    "                    \"name\": image_dict['name'][i],\n",
    "                    \"appearance\": '容姿'\n",
    "                })]\n",
    "            )\n",
    "    print(\"Image Summaries Data Stored!!\")    \n",
    "    \n",
    "    # metadataとして登録したもののattributeを定義\n",
    "    metadata_field_info = [\n",
    "        AttributeInfo(\n",
    "            name=\"name\",\n",
    "            description=\"Character Name\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"birthday\",\n",
    "            description=\"Character Birthday\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"birthday_month\",\n",
    "            description=\"Character Birthday Month\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"birthday_day\",\n",
    "            description=\"Character Birthday Day\",\n",
    "            type=\"string\",\n",
    "        ),         \n",
    "        AttributeInfo(\n",
    "            name=\"sex\",\n",
    "            description=\"Character Sex\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        AttributeInfo(\n",
    "            name=\"appearance\",\n",
    "            description=\"Character Image Description\",\n",
    "            type=\"string\",\n",
    "        ),          \n",
    "    ]\n",
    "    \n",
    "    # フィルタ作成に使用するLLMの定義\n",
    "    document_content_description = \"モンスターストライク(モンスト)におけるキャラクターの情報と容姿についての説明\"\n",
    "    if model_name == \"\":\n",
    "        model_name = \"gemini-1.5-pro-preview-0409\"\n",
    "        llm = ChatVertexAI(model_name=model_name)\n",
    "    \n",
    "    # TODO\n",
    "    return SelfQueryRetriever.from_llm(\n",
    "        llm=____,\n",
    "        vectorstore=____,\n",
    "        document_contents=___, \n",
    "        metadata_field_info=____,\n",
    "        verbose=True,\n",
    "        chain_kwargs={\n",
    "            \"examples\": examples\n",
    "        },\n",
    "        search_kwargs={\n",
    "            \"k\": 4\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9652038-0af2-4b40-ac76-5d269b379026",
   "metadata": {},
   "source": [
    "また、変数としてメソッド内で定義されていないexamplesを引数として受け取り、  \n",
    "Retrieverに渡していますが、これは、filter作成の精度向上のため、  \n",
    "いくつかの事例を用意して渡すための変数となります。  \n",
    "下記の形で、いくつか定義しておきます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b95f7-d953-4179-91af-2a5a34a8c078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"誕生日が03月01日のキャラクターはなんですか？\",\n",
    "        {\n",
    "            \"query\": \"誕生日が3月1日のキャラクター\",\n",
    "            \"filter\": 'and(eq(\"birthday_month\", \"3\"), eq(\"birthday_day\", \"1\"))',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"ルシファーについて教えてください\",\n",
    "        {\n",
    "            \"query\": \"ルシファーについて教えてください\",\n",
    "            \"filter\": 'eq(\"name\", \"ルシファー\")',\n",
    "        },\n",
    "    ),    \n",
    "    (\n",
    "        \"ルシファーの画像をください\",\n",
    "        {\n",
    "            \"query\": \"ルシファーの画像\",\n",
    "            \"filter\": 'and(eq(\"name\", \"ルシファー\"), eq(\"appearance\", \"容姿\"))',\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"ルシファーの容姿を教えてください\",\n",
    "        {\n",
    "            \"query\": \"ルシファーの容姿\",\n",
    "            \"filter\": 'and(eq(\"name\", \"ルシファー\"), eq(\"appearance\", \"容姿\"))',\n",
    "        },\n",
    "    )    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3118f-9d4e-47e3-841d-5452aef0b9eb",
   "metadata": {},
   "source": [
    "それでは、self_query_retrieverを作っていきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a304e8c-298b-4d0d-9d5a-42ec948a3a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_query_retriever = get_self_query_retriever(\n",
    "    text_dict, image_dict, metadata_dict, examples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38481a5c-7f2a-4a6a-b978-720b8397bd6e",
   "metadata": {},
   "source": [
    "完成したら、関連するドキュメントをとって精度を確認してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f894e1b-f7b0-48cc-b607-89f94d430d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_query_retriever.invoke(\"誕生日が7月7日のキャラクターを教えてください\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479840c-684a-4bdc-b9cb-5cbb96fe9ed5",
   "metadata": {},
   "source": [
    "精度はどうでしょうか  \n",
    "問題なければ、これでretrieverの定義は完了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0817e-adc9-4552-aaf9-b8010c94f1aa",
   "metadata": {},
   "source": [
    "# Chainの作成  \n",
    "では、最後に質問からドキュメントの検索を行い、関連情報を含めたプロンプトを作成し  \n",
    "LLMから回答を受け取るまでのフローを作成していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392c238-df59-4a8f-b4bb-5120789a8bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAI, HarmCategory, HarmBlockThreshold\n",
    "from vertexai import generative_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1893a5-1ec2-44b8-a35c-ab8526405f76",
   "metadata": {},
   "source": [
    "モンストディクショナリーの情報を使った検索にあたり、強めのワードに関する制限をオフにする設定を定義します。  \n",
    "これは、モンストの世界はあくまでゲームの世界のため、強い表現があり(「下僕」など)、  \n",
    "それが制限に引っかかる可能性があるためです。  \n",
    "しかし、実際にサービスに入れるときなどはこれらの設定を適切に設定することを心に留めておいてください。  \n",
    "また、今回のモデルに置いても **社会良俗に反することは入力しない** ようにしてください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a087014-c2d8-4010-819e-8c9ff7c81fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "safety_settings = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac05ecd-e957-4247-97a4-7a2357e310ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "Chainを作る際に呼び出すメソッドを定義していきます。  \n",
    "まず、generate_promptメソッドを用意します。  \n",
    "このメソッドは、各retrieverから受け取った関連情報を使い最終的なLLMへの入力となるテキストのプロンプトを作成します。  \n",
    "また、受け取った関連情報に画像の要約の情報が含まれていたら、画像を出力するようにすると同時に、  \n",
    "LLMの入力に画像を含んだデータを渡すようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c44b28-3dad-430b-89f2-7d5dd52f042b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from base64 import b64encode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plt_image(image_data):\n",
    "    image = Image.open(image_data)\n",
    "    # 画像を表示\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_prompt(data):\n",
    "    prompt_template = f\"\"\"\n",
    "        contextや画像には、モンスターストライク(通称モンスト)のキャラクター情報が与えられます。\n",
    "        以下の質問に対して、モンストと関連する質問に対しては、contextおよび写真を参考にして質問に答えてください。\n",
    "        なお、contextには質問と関係ないものが入ることもありますので、その場合は無視をしてください。\n",
    "        画像に対しても、関係ない場合は無視をしてください。\n",
    "        モンストと関連する質問に対し、contextや内容を使ってもわからなかった場合は、分かりませんという回答をしてください。\n",
    "        モンストに関連する質問でないと判断した場合は、contextの情報や画像の情報を使わず、内容に対しての回答をしてください。\n",
    "\n",
    "        内容:\n",
    "        {data[\"question\"]}\n",
    "\n",
    "        context1:\n",
    "        {data[\"context1\"]}\n",
    "        \n",
    "        context2:\n",
    "        {data[\"context2\"]}    \n",
    "        \"\"\"\n",
    "    text_message = {\"type\": \"text\", \"text\": prompt_template}\n",
    "\n",
    "    # 画像がRetrivalで取得された場合には画像を追加,エンコードしてmatplotlibで表示する\n",
    "    # context2の関連性が最も高い要素が'容姿'だった場合モデルに画像を含めて入力する\n",
    "    if len(data[\"context2\"]) > 0 and use_image:\n",
    "        doc = data[\"context2\"][0]\n",
    "        if 'appearance' in doc.metadata:\n",
    "            name = doc.metadata['name']\n",
    "            name_path = f\"monst_dic/images/{name}.png\"\n",
    "            print(name_path)\n",
    "            try:\n",
    "                image_data = bucket.read_file_from_gcs(name_path)\n",
    "            except:\n",
    "                print(\"gcsのbucketが認識できていません。　設定するか、use_imageをfalseにしてください・\")\n",
    "            plt_image(image_data)\n",
    "            image_b64 = b64encode(image_data.getvalue()).decode(\"utf-8\")\n",
    "            image_url = f\"data:image/jpeg;base64,{image_b64}\"\n",
    "            image_message = {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            return [HumanMessage(content=[text_message, image_message])]\n",
    "    return [HumanMessage(content=[text_message])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee7510-70ad-49ac-a261-6bffc6b5b82e",
   "metadata": {
    "tags": []
   },
   "source": [
    "次に、get_response_from_modelを定義します。  \n",
    "これは、generate_promptで生成されたpromptを使ってGemini Proに質問を投げ、  \n",
    "返ってきた返答を返しているだけのメソッドとなります。\n",
    "\n",
    "## TODO\n",
    "事前に定義したVertexAIのgeminiモデルを埋めてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b0391c-8056-4f63-9aaf-ffc2390217a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# モデルにqueryを投げて返答を受け取る\n",
    "def get_response_from_model(message, model_name = \"\"):\n",
    "    if model_name == \"\":\n",
    "        model_name = \"gemini-1.5-pro-preview-0409\"\n",
    "    # TODO\n",
    "    model = ____(model_name=model_name, safety_settings=safety_settings)\n",
    "    response = model(message)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901917b-adb6-48e5-88c3-81d9d62f4da7",
   "metadata": {},
   "source": [
    "最後にこれらのメソッドを使ってチェインを定義していきましょう。\n",
    "\n",
    "## TODO\n",
    "穴あき箇所に定義した関数を埋めてchainを完成させてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d0885-a39e-4af8-8081-e43988f5b267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "\n",
    "# Chainを作成、実行する\n",
    "def multimodal_rag(parent_retriever, self_query_retriever , question: str) -> str:\n",
    "    chain = (\n",
    "        {\n",
    "            \"context1\": parent_retriever,\n",
    "            \"context2\": self_query_retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        # TODO\n",
    "        | RunnableLambda(____)\n",
    "        | RunnableLambda(____)\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    answer = chain.invoke(question)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7759dc-a2b6-4b41-b25d-02b431ce6bba",
   "metadata": {},
   "source": [
    "これで、RAGを用いた文書検索部分の実装は完了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46184496-df33-4066-87e0-9f829465c21e",
   "metadata": {},
   "source": [
    "# 結果の確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513ec57-ec75-4d39-9a14-5cda9970b9fb",
   "metadata": {},
   "source": [
    "では、questionに質問を用意し、結果の確認をしてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8275cb0-9c23-4e2c-8b1e-940e2e0db106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_1 = \"誕生日が1/1のキャラクターを教えてください\"\n",
    "answer_1 = multimodal_rag(parent_retriever, self_query_retriever, question_1)\n",
    "Markdown(answer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318f0a7-b42b-455b-8224-52f16b724da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_2 = \"モンストのネオについて、画像も含めて詳細に教えてください。\"\n",
    "answer_2 = multimodal_rag(parent_retriever, self_query_retriever, question_2)\n",
    "Markdown(answer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d0a60-d0f9-49d7-be05-0ed0fc092732",
   "metadata": {
    "tags": []
   },
   "source": [
    "モンストディクショナリーを参考に、正しい情報を出力することができたでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69822645-5398-4980-867a-3c1a9cdd0905",
   "metadata": {},
   "source": [
    "好きな質問を入れて、どんな出力を得られるか試してみましょう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb2ba2-789d-4735-9406-3d8e7be7a12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo 好きな検索を入れてみよう\n",
    "question = \"モンストにおいて、容姿が金髪である女性キャラクターを教えてください。\"\n",
    "answer = multimodal_rag(parent_retriever, self_query_retriever, question)\n",
    "Markdown(answer)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
