{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-beijing",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-horse",
   "metadata": {},
   "source": [
    "このハンズオンでは、modelのpruningを行い、得られる効果を確認していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proved-neighborhood",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tracked-paint",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 06:10:57.402057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 06:10:58.391423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-04-17 06:10:58.391529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-04-17 06:10:58.391538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-empire",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "評価で使用するため、再度Fashion-MNISTデータセットをロードして、\n",
    "前処理も行なっておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "authentic-hepatitis",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28, 1)\n",
      "X_test shape (10000, 28, 28, 1)\n",
      "one hot label shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = fashion_mnist.load_data()\n",
    "\n",
    "## shapeを(batch_size, rows, cols, channels)にexpandする\n",
    "X_train = np.expand_dims(X_train_orig, -1)\n",
    "X_test = np.expand_dims(X_test_orig, -1)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "\n",
    "## グレースケールの 0-255 の値を 正規化して 0-1 の浮動小数にする\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "## one hot vectorにする\n",
    "y_train = tf.keras.utils.to_categorical(y_train_orig, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test_orig, 10)\n",
    "\n",
    "print(\"one hot label shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-layer",
   "metadata": {},
   "source": [
    "### モデルのロード\n",
    "01で保存したFashion-MNISTモデルをロードします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "usual-renaissance",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 06:11:06.191471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:06.205875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:06.209591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:06.213400: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 06:11:06.213814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:06.217255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:06.221777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:07.126792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:07.129053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:07.130983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-17 06:11:07.132819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13609 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "## <todo> 自分の名前を入力してください\n",
    "USER    = \"test\" # 自分の名前\n",
    "BUCKET  = \"mixi-ml-handson-2024\"\n",
    "MODEL = \"fmnist_model\"\n",
    "\n",
    "base_model = tf.keras.models.load_model(\"gs://{}/{}/{}\".format(BUCKET, USER, MODEL))\n",
    "\n",
    "# ベースモデルを一時保存しておく\n",
    "_, base_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(base_model, base_model_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-china",
   "metadata": {},
   "source": [
    "### ベースモデルの精度確認\n",
    "再度、ベースモデルの評価を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comic-kazakhstan",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 06:11:14.579858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 4s 3ms/step - loss: 0.2380 - categorical_accuracy: 0.9178\n",
      "loss: 0.23802654445171356, Accuracy: 0.9178000092506409\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = base_model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(\"loss: {}, Accuracy: {}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-pocket",
   "metadata": {},
   "source": [
    "### 重みの確認\n",
    "\n",
    "pruningとは、重みが小さいエッジを取り去って、パラメータを削減する手法です。  \n",
    "パラメータが少なくなれば、その分モデルのサイズは小さくなり、高速化されます。  \n",
    "しかし、今回のモデルの重みに削減する余地はあるでしょうか。\n",
    "\n",
    "実際に重みの値を確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-disease",
   "metadata": {},
   "source": [
    "まず、再度モデルの構成を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "close-warehouse",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               819328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,362\n",
      "Trainable params: 876,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-receipt",
   "metadata": {},
   "source": [
    "この中のうち、`conv2d`と`dense`が層を構成しています。  \n",
    "これらの層の重みからヒストグラムを作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excellent-breach",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_weights_histgram(model, layers_index, bins=1000):\n",
    "    ## <todo> ___を埋めて指定したindexのweightsを渡せるようにしましょう\n",
    "    weight_list = model.layers[layers_index].weights[0].numpy().flatten()\n",
    "    plt.hist(weight_list, bins=bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grateful-teddy",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## <todo>引数 layers_indexの部分にconv2dまたはdense層のindexを入れて、それぞれの重みをplotしてみましょう\n",
    "## ヒント: モデルの構成を参考にしてみてください\n",
    "## weightsの総数が少ない場合は、binsの値を小さくしてplotしてみてください\n",
    "draw_weights_histgram(base_model, layers_index=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-insight",
   "metadata": {},
   "source": [
    "だいたいどの層をplotしてみても、0.0付近に値が集中していたのではないでしょうか。  \n",
    "0.0付近のweightは、消去しても精度に大きな影響を与えないはずなので、このモデルにはpruningする余地が十分あるといえそうです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-entrance",
   "metadata": {},
   "source": [
    "### pruningモデルを定義\n",
    "公式の[Pruning in Keras example](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)を参考にpruningモデルを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "military-evening",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def compute_necessary_steps(batch_size, epochs):\n",
    "    return np.ceil(X_train.shape[0] / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "end_step = compute_necessary_steps(batch_size=16, epochs=5)\n",
    "\n",
    "# 最初に10%をpruning、最終的には70%をpruningする様にスケジューリング\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.10,\n",
    "        final_sparsity=0.70,\n",
    "        begin_step=0,\n",
    "        end_step=end_step\n",
    "    )\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(base_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prompt-blanket",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_for_pruning.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-denial",
   "metadata": {},
   "source": [
    "### 学習\n",
    "pruningモデルが定義できたので、再学習させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fifty-organic",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 06:16:05.126923: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f60ac4e1fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-17 06:16:05.126982: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-04-17 06:16:05.133138: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-17 06:16:05.287873: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/3375 [..............................] - ETA: 7:35:32 - loss: 0.1768 - categorical_accuracy: 0.9375WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.0154s). Check your callbacks.\n",
      "3375/3375 [==============================] - 31s 7ms/step - loss: 0.2067 - categorical_accuracy: 0.9244 - val_loss: 0.2079 - val_categorical_accuracy: 0.9255\n",
      "Epoch 2/5\n",
      "3375/3375 [==============================] - 23s 7ms/step - loss: 0.2082 - categorical_accuracy: 0.9252 - val_loss: 0.2187 - val_categorical_accuracy: 0.9238\n",
      "Epoch 3/5\n",
      "3375/3375 [==============================] - 24s 7ms/step - loss: 0.2178 - categorical_accuracy: 0.9214 - val_loss: 0.2107 - val_categorical_accuracy: 0.9252\n",
      "Epoch 4/5\n",
      "3375/3375 [==============================] - 23s 7ms/step - loss: 0.2212 - categorical_accuracy: 0.9202 - val_loss: 0.2114 - val_categorical_accuracy: 0.9258\n",
      "Epoch 5/5\n",
      "3375/3375 [==============================] - 24s 7ms/step - loss: 0.2130 - categorical_accuracy: 0.9231 - val_loss: 0.2008 - val_categorical_accuracy: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60d849a590>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%rm -rf ./pruning_logs\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='pruning_logs'),\n",
    "]\n",
    "model_for_pruning.fit(X_train, y_train, batch_size=16, epochs=5, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-median",
   "metadata": {},
   "source": [
    "### 評価\n",
    "学習が終わったら、これまでと同じように評価してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "derived-fifty",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2247 - categorical_accuracy: 0.9225\n",
      "loss: 0.224664568901062, Accuracy: 0.9225000143051147\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_for_pruning.evaluate(X_test, y_test, batch_size=16)\n",
    "print(\"loss: {}, Accuracy: {}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-steel",
   "metadata": {},
   "source": [
    "モデルの精度はベースモデルと比較してどうなっているでしょうか。  \n",
    "ほとんど変わってなければ、精度に影響を与えずにpruningされていることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-dispatch",
   "metadata": {},
   "source": [
    "### 可視化\n",
    "01と同じように、学習結果をtensorboardで可視化してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eligible-tomorrow",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proper-asbestos",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f62bdb8430cf476e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f62bdb8430cf476e\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir pruning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-theater",
   "metadata": {},
   "source": [
    "学習の推移やshcedule通りにpruningされていったかなどを確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-maple",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pruningモデルを圧縮\n",
    "pruningすることが出来たので、モデルの圧縮を行いましょう。\n",
    "\n",
    "[公式](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras#create_3x_smaller_models_from_pruning)によると、圧縮を確認するには`tfmot.sparsity.keras.strip_pruning`と標準の圧縮アルゴリズムの適用（gzipなど）の両方が必要とのことなので、\n",
    "その対応をしていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "variable-cheese",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "## <todo> 公式を参考に___を埋めてpruningしたmodelにstrip_pruningを適応しましょう\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "# pruningしたモデルを一時保存\n",
    "_, pruned_model_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_model_file, include_optimizer=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "loaded-cambridge",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gzipを適応した後のsizeをkbで返す関数\n",
    "def get_gzipped_model_size_kb(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return int(os.path.getsize(zipped_file) / 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-assignment",
   "metadata": {},
   "source": [
    "準備ができたので、各モデルにおける圧縮の効果を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hispanic-neighborhood",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model size    : 3201 kb\n",
      "pruned model size : 1325 kb\n"
     ]
    }
   ],
   "source": [
    "print(\"base model size    : {} kb\".format(get_gzipped_model_size_kb(base_model_file)))\n",
    "print(\"pruned model size : {} kb\".format(get_gzipped_model_size_kb(pruned_model_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-chocolate",
   "metadata": {},
   "source": [
    "モデルが1/3ほどに圧縮されたことが確認できているでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-democrat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
